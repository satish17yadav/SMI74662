from SimplerLLM.tools.text_chunker import chunk_by_paragraphs
from scipy.spatial.distance import cosine
import time 
import resources
import openai

def search_semantically_similar(text):
    chunks = chunk_by_paragraphs(text)
    article_paragraphs = chunk_by_paragraphs(resources.article_two) 
    all_comparisons = 0  
    plagiarised_chunks = 0 
    for chunk in chunks.chunks:
        chunk_vector = convert_to_vector(chunk.text)
            
        for paragraph in article_paragraphs.chunks: 
            if paragraph.text.strip():  
                all_comparisons += 1  
                paragraph_vector = convert_to_vector(paragraph.text) 
                similarity = calculate_cosine_similarity(chunk_vector, paragraph_vector)  
                
                if is_similarity_significant(similarity):                  plagiarised_chunks += 1  
        
    plagiarism_score = ((plagiarised_chunks / all_comparisons) * 100) 
    return plagiarism_score  
def convert_to_vector(text):
        text = text.replace("\n", " ") 
    response = openai.embeddings.create(
        input=[text],
        model="text-embedding-3-small"
    )
    return response.data[0].embedding 
def calculate_cosine_similarity(vec1, vec2):
    
    return 1 - cosine(vec1, vec2)  
def is_similarity_significant(similarity_score):
    
        threshold = 0.7
    return similarity_score >= threshold 
start_time = time.time()  
text_to_check = resources.article_one
plagiarism_score = search_semantically_similar(text_to_check) 
end_time = time.time()  
runtime = end_time - start_time  
print(f"Plagiarism Score: {plagiarism_score}%")
print(f"Runtime: {runtime} seconds")  
